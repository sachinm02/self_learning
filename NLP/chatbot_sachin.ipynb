{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer Chat Bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "     \n",
    "     We will be working with the Babi Data Set from Facebook Research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_qa.txt','rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_qa.txt','rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data),type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0] #each item is tuple of a story,question,answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0] #each item is tuple of a story,question,answer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data+test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 11000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_data),len(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37,\n",
       " {'.',\n",
       "  '?',\n",
       "  'Daniel',\n",
       "  'Is',\n",
       "  'John',\n",
       "  'Mary',\n",
       "  'Sandra',\n",
       "  'apple',\n",
       "  'back',\n",
       "  'bathroom',\n",
       "  'bedroom',\n",
       "  'discarded',\n",
       "  'down',\n",
       "  'dropped',\n",
       "  'football',\n",
       "  'garden',\n",
       "  'got',\n",
       "  'grabbed',\n",
       "  'hallway',\n",
       "  'in',\n",
       "  'journeyed',\n",
       "  'kitchen',\n",
       "  'left',\n",
       "  'milk',\n",
       "  'moved',\n",
       "  'no',\n",
       "  'office',\n",
       "  'picked',\n",
       "  'put',\n",
       "  'the',\n",
       "  'there',\n",
       "  'to',\n",
       "  'took',\n",
       "  'travelled',\n",
       "  'up',\n",
       "  'went',\n",
       "  'yes'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set()\n",
    "for story,question,asnwer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "    \n",
    "vocab.add('yes')\n",
    "vocab.add('no')\n",
    "\n",
    "len(vocab),vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(vocab) + 1\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating lengths of all Stories and Questions in data and taking maximum value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_length = max([len(data[0]) for data in all_data])\n",
    "max_story_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_length = max([len(data[1]) for data in all_data])\n",
    "max_question_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'back': 1,\n",
       " 'travelled': 2,\n",
       " 'milk': 3,\n",
       " 'john': 4,\n",
       " 'apple': 5,\n",
       " 'discarded': 6,\n",
       " 'garden': 7,\n",
       " 'in': 8,\n",
       " 'mary': 9,\n",
       " 'there': 10,\n",
       " 'got': 11,\n",
       " '?': 12,\n",
       " '.': 13,\n",
       " 'went': 14,\n",
       " 'moved': 15,\n",
       " 'to': 16,\n",
       " 'picked': 17,\n",
       " 'bedroom': 18,\n",
       " 'daniel': 19,\n",
       " 'kitchen': 20,\n",
       " 'put': 21,\n",
       " 'left': 22,\n",
       " 'up': 23,\n",
       " 'football': 24,\n",
       " 'took': 25,\n",
       " 'office': 26,\n",
       " 'journeyed': 27,\n",
       " 'is': 28,\n",
       " 'sandra': 29,\n",
       " 'bathroom': 30,\n",
       " 'the': 31,\n",
       " 'dropped': 32,\n",
       " 'down': 33,\n",
       " 'yes': 34,\n",
       " 'no': 35,\n",
       " 'hallway': 36,\n",
       " 'grabbed': 37}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('no', 18)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Methods for Fetching data from Tokenizer\n",
    "tokenizer.index_word[35],tokenizer.word_index['bedroom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_story_text = [data[0] for data in train_data]\n",
    "# train_question_text = [data[1] for data in train_data]\n",
    "# train_answer_text = [data[2] for data in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Vectorizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(data,word_index,max_story_len,max_ques_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    \n",
    "    # iterating over all the data\n",
    "    for story,question,answer in data:\n",
    "        \n",
    "        # conveting to sequence of numbers from text\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        # Creating a row with all zeroes\n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        \n",
    "        # Setting the value at index of yes/no = 1\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # appending generated lists to our main list\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "    X = pad_sequences(X,maxlen=max_story_length)\n",
    "    Xq = pad_sequences(Xq,maxlen=max_question_length)\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    # Returning tuple for unpacking\n",
    "    return (X,Xq,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_train,question_train,answer_train = vectorize_data(data=train_data,word_index=tokenizer.word_index,\n",
    "                                                      max_story_len=max_story_length,max_ques_len=max_question_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_test,question_test,answer_test = vectorize_data(data=test_data,word_index=tokenizer.word_index,\n",
    "                                                      max_story_len=max_story_length,max_ques_len=max_question_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model\n",
    "\n",
    "### NOTE:\n",
    "    We are going to use \"End-to-End Memory Networks\" architecture, so steps will be according to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input,Activation,Dense,Dropout,Permute\n",
    "from keras.layers import dot,concatenate,add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Place holders for our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_seq = Input(shape=(max_story_length,))\n",
    "question_seq = Input(shape=(max_question_length,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder : Memory Vector Representation (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sachin/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim=64))\n",
    "input_encoder_m.add(Dropout(rate=0.3))\n",
    "# output: (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder : Output Vector Representation (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim=max_question_length))\n",
    "input_encoder_c.add(Dropout(rate=0.3))\n",
    "# output: (samples, story_maxlen, ques_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder (u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim=64,input_length=max_question_length))\n",
    "question_encoder.add(Dropout(rate=0.3))\n",
    "# output: (samples, ques_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(story_seq)\n",
    "input_encoded_c = input_encoder_c(story_seq)\n",
    "question_encoded = question_encoder(question_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the dot product between input memory embedding and question embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m,question_encoded],axes=(2,2))\n",
    "match = Activation(activation='softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the weighted sum of output memory embeddding and computed match matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match,input_encoded_c]) # (samples, story_maxlen, ques_maxlen)\n",
    "response = Permute(dims=(2,1))(response) # (samples, ques_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the Output and Question embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = concatenate([response,question_encoded])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_1/strided_slice_18:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce with RNN(LSTM)\n",
    "answer = LSTM(32)(answer)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 38) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(units=vocab_len)(answer)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_2/Softmax:0' shape=(?, 38) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = Activation(activation='softmax')(answer)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Model([story_seq,question_seq],answer)\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sachin/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/sachin/anaconda3/envs/nlp_course/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 8s 790us/step - loss: 0.9063 - accuracy: 0.4963 - val_loss: 0.7004 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 6s 614us/step - loss: 0.7036 - accuracy: 0.4974 - val_loss: 0.6934 - val_accuracy: 0.5030\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.6967 - accuracy: 0.4979 - val_loss: 0.6944 - val_accuracy: 0.4970\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 6s 609us/step - loss: 0.6952 - accuracy: 0.4977 - val_loss: 0.6933 - val_accuracy: 0.4970\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 7s 668us/step - loss: 0.6952 - accuracy: 0.4998 - val_loss: 0.6940 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.6949 - accuracy: 0.4969 - val_loss: 0.6938 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 0.6944 - accuracy: 0.4983 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 8s 774us/step - loss: 0.6946 - accuracy: 0.4947 - val_loss: 0.6936 - val_accuracy: 0.4900\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.6940 - accuracy: 0.5095 - val_loss: 0.6946 - val_accuracy: 0.5020\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 6s 562us/step - loss: 0.6940 - accuracy: 0.5020 - val_loss: 0.6941 - val_accuracy: 0.5010\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.6893 - accuracy: 0.5358 - val_loss: 0.6823 - val_accuracy: 0.5740\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 0.6515 - accuracy: 0.6072 - val_loss: 0.5808 - val_accuracy: 0.7140\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 6s 597us/step - loss: 0.5416 - accuracy: 0.7395 - val_loss: 0.4716 - val_accuracy: 0.7780\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 7s 651us/step - loss: 0.4654 - accuracy: 0.7941 - val_loss: 0.4312 - val_accuracy: 0.8120\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 7s 653us/step - loss: 0.4277 - accuracy: 0.8211 - val_loss: 0.4219 - val_accuracy: 0.8300\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 6s 621us/step - loss: 0.3968 - accuracy: 0.8372 - val_loss: 0.3916 - val_accuracy: 0.8290\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.3775 - accuracy: 0.8443 - val_loss: 0.3785 - val_accuracy: 0.8380\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 6s 592us/step - loss: 0.3636 - accuracy: 0.8498 - val_loss: 0.3874 - val_accuracy: 0.8290\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 6s 641us/step - loss: 0.3536 - accuracy: 0.8510 - val_loss: 0.3699 - val_accuracy: 0.8310\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.3416 - accuracy: 0.8546 - val_loss: 0.3805 - val_accuracy: 0.8420\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.3307 - accuracy: 0.8588 - val_loss: 0.3482 - val_accuracy: 0.8370\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 6s 605us/step - loss: 0.3272 - accuracy: 0.8606 - val_loss: 0.3480 - val_accuracy: 0.8370\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.3237 - accuracy: 0.8620 - val_loss: 0.3416 - val_accuracy: 0.8410\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 5s 543us/step - loss: 0.3205 - accuracy: 0.8599 - val_loss: 0.3320 - val_accuracy: 0.8380\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 5s 544us/step - loss: 0.3166 - accuracy: 0.8633 - val_loss: 0.3410 - val_accuracy: 0.8440\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 0.3098 - accuracy: 0.8641 - val_loss: 0.3341 - val_accuracy: 0.8310\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.3129 - accuracy: 0.8659 - val_loss: 0.3327 - val_accuracy: 0.8490\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 6s 616us/step - loss: 0.3124 - accuracy: 0.8622 - val_loss: 0.3282 - val_accuracy: 0.8440\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 6s 603us/step - loss: 0.3086 - accuracy: 0.8640 - val_loss: 0.3346 - val_accuracy: 0.8310\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.3027 - accuracy: 0.8673 - val_loss: 0.3541 - val_accuracy: 0.8310\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 6s 613us/step - loss: 0.3010 - accuracy: 0.8652 - val_loss: 0.3313 - val_accuracy: 0.8510\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 6s 648us/step - loss: 0.3048 - accuracy: 0.8642 - val_loss: 0.3423 - val_accuracy: 0.8280\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.3001 - accuracy: 0.8639 - val_loss: 0.3513 - val_accuracy: 0.8260\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 6s 599us/step - loss: 0.2981 - accuracy: 0.8676 - val_loss: 0.3461 - val_accuracy: 0.8450\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.2969 - accuracy: 0.8679 - val_loss: 0.3348 - val_accuracy: 0.8450\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.2975 - accuracy: 0.8659 - val_loss: 0.3702 - val_accuracy: 0.8170\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 6s 591us/step - loss: 0.2964 - accuracy: 0.8685 - val_loss: 0.3422 - val_accuracy: 0.8450\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 7s 689us/step - loss: 0.2968 - accuracy: 0.8655 - val_loss: 0.3267 - val_accuracy: 0.8430\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 6s 639us/step - loss: 0.2943 - accuracy: 0.8684 - val_loss: 0.3355 - val_accuracy: 0.8410\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 7s 726us/step - loss: 0.2877 - accuracy: 0.8715 - val_loss: 0.3321 - val_accuracy: 0.8460\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 7s 740us/step - loss: 0.2852 - accuracy: 0.8728 - val_loss: 0.3379 - val_accuracy: 0.8400\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 7s 698us/step - loss: 0.2927 - accuracy: 0.8694 - val_loss: 0.3541 - val_accuracy: 0.8340\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.2883 - accuracy: 0.8717 - val_loss: 0.3594 - val_accuracy: 0.8360\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.2924 - accuracy: 0.8657 - val_loss: 0.3324 - val_accuracy: 0.8450\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.2888 - accuracy: 0.8694 - val_loss: 0.3557 - val_accuracy: 0.8430\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 6s 624us/step - loss: 0.2916 - accuracy: 0.8695 - val_loss: 0.3432 - val_accuracy: 0.8450\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 6s 622us/step - loss: 0.2861 - accuracy: 0.8706 - val_loss: 0.3575 - val_accuracy: 0.8450\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 6s 587us/step - loss: 0.2852 - accuracy: 0.8719 - val_loss: 0.3423 - val_accuracy: 0.8420\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 6s 606us/step - loss: 0.2889 - accuracy: 0.8711 - val_loss: 0.3482 - val_accuracy: 0.8350\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 6s 593us/step - loss: 0.2855 - accuracy: 0.8724 - val_loss: 0.3391 - val_accuracy: 0.8370\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 596us/step - loss: 0.2818 - accuracy: 0.8725 - val_loss: 0.3411 - val_accuracy: 0.8400\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 6s 573us/step - loss: 0.2887 - accuracy: 0.8664 - val_loss: 0.3401 - val_accuracy: 0.8390\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 6s 604us/step - loss: 0.2831 - accuracy: 0.8719 - val_loss: 0.3448 - val_accuracy: 0.8400\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 6s 587us/step - loss: 0.2856 - accuracy: 0.8725 - val_loss: 0.3567 - val_accuracy: 0.8400\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 6s 596us/step - loss: 0.2828 - accuracy: 0.8722 - val_loss: 0.3445 - val_accuracy: 0.8420\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 6s 582us/step - loss: 0.2787 - accuracy: 0.8698 - val_loss: 0.3612 - val_accuracy: 0.8360\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.2821 - accuracy: 0.8752 - val_loss: 0.3536 - val_accuracy: 0.8380\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.2825 - accuracy: 0.8734 - val_loss: 0.3468 - val_accuracy: 0.8370\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 0.2768 - accuracy: 0.8744 - val_loss: 0.3472 - val_accuracy: 0.8350\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 6s 598us/step - loss: 0.2763 - accuracy: 0.8781 - val_loss: 0.3973 - val_accuracy: 0.8350\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 6s 605us/step - loss: 0.2735 - accuracy: 0.8766 - val_loss: 0.3636 - val_accuracy: 0.8390\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 6s 593us/step - loss: 0.2747 - accuracy: 0.8738 - val_loss: 0.3598 - val_accuracy: 0.8340\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 7s 680us/step - loss: 0.2749 - accuracy: 0.8763 - val_loss: 0.3579 - val_accuracy: 0.8380\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 7s 666us/step - loss: 0.2752 - accuracy: 0.8786 - val_loss: 0.3557 - val_accuracy: 0.8390\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 6s 633us/step - loss: 0.2713 - accuracy: 0.8784 - val_loss: 0.3615 - val_accuracy: 0.8430\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 6s 641us/step - loss: 0.2707 - accuracy: 0.8805 - val_loss: 0.3702 - val_accuracy: 0.8340\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 7s 659us/step - loss: 0.2719 - accuracy: 0.8805 - val_loss: 0.3574 - val_accuracy: 0.8370\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 0.2707 - accuracy: 0.8831 - val_loss: 0.3690 - val_accuracy: 0.8400\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 6s 646us/step - loss: 0.2662 - accuracy: 0.8804 - val_loss: 0.3906 - val_accuracy: 0.8250\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 0.2644 - accuracy: 0.8830 - val_loss: 0.3714 - val_accuracy: 0.8420\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 0.2591 - accuracy: 0.8846 - val_loss: 0.3915 - val_accuracy: 0.8360\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 0.2616 - accuracy: 0.8825 - val_loss: 0.3981 - val_accuracy: 0.8320\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 6s 641us/step - loss: 0.2587 - accuracy: 0.8835 - val_loss: 0.3721 - val_accuracy: 0.8380\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 6s 633us/step - loss: 0.2597 - accuracy: 0.8872 - val_loss: 0.4253 - val_accuracy: 0.8250\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 0.2603 - accuracy: 0.8856 - val_loss: 0.3978 - val_accuracy: 0.8390\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 6s 640us/step - loss: 0.2558 - accuracy: 0.8891 - val_loss: 0.3940 - val_accuracy: 0.8410\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 7s 659us/step - loss: 0.2552 - accuracy: 0.8862 - val_loss: 0.3967 - val_accuracy: 0.8440\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 6s 647us/step - loss: 0.2612 - accuracy: 0.8899 - val_loss: 0.3755 - val_accuracy: 0.8390\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 7s 651us/step - loss: 0.2504 - accuracy: 0.8911 - val_loss: 0.3963 - val_accuracy: 0.8430\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 0.2557 - accuracy: 0.8897 - val_loss: 0.3929 - val_accuracy: 0.8340\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 6s 634us/step - loss: 0.2508 - accuracy: 0.8888 - val_loss: 0.3847 - val_accuracy: 0.8430\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 6s 639us/step - loss: 0.2561 - accuracy: 0.8885 - val_loss: 0.3996 - val_accuracy: 0.8440\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 0.2484 - accuracy: 0.8922 - val_loss: 0.4214 - val_accuracy: 0.8480\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 7s 661us/step - loss: 0.2486 - accuracy: 0.8927 - val_loss: 0.3910 - val_accuracy: 0.8440\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 0.2418 - accuracy: 0.8945 - val_loss: 0.4150 - val_accuracy: 0.8350\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 7s 654us/step - loss: 0.2400 - accuracy: 0.8980 - val_loss: 0.4209 - val_accuracy: 0.8490\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 6s 636us/step - loss: 0.2365 - accuracy: 0.8959 - val_loss: 0.5291 - val_accuracy: 0.8140\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 7s 652us/step - loss: 0.2414 - accuracy: 0.8947 - val_loss: 0.4190 - val_accuracy: 0.8410\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 7s 651us/step - loss: 0.2400 - accuracy: 0.8938 - val_loss: 0.3894 - val_accuracy: 0.8440\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 0.2321 - accuracy: 0.8993 - val_loss: 0.4003 - val_accuracy: 0.8430\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 6s 642us/step - loss: 0.2421 - accuracy: 0.8987 - val_loss: 0.4442 - val_accuracy: 0.8490\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 6s 650us/step - loss: 0.2309 - accuracy: 0.9010 - val_loss: 0.4161 - val_accuracy: 0.8510\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 6s 639us/step - loss: 0.2315 - accuracy: 0.8995 - val_loss: 0.4418 - val_accuracy: 0.8500\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 7s 651us/step - loss: 0.2292 - accuracy: 0.9021 - val_loss: 0.4551 - val_accuracy: 0.8500\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 6s 650us/step - loss: 0.2280 - accuracy: 0.9038 - val_loss: 0.4023 - val_accuracy: 0.8520\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 0.2195 - accuracy: 0.9060 - val_loss: 0.4421 - val_accuracy: 0.8190\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 6s 645us/step - loss: 0.2217 - accuracy: 0.9050 - val_loss: 0.4292 - val_accuracy: 0.8460\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 7s 658us/step - loss: 0.2235 - accuracy: 0.9074 - val_loss: 0.4018 - val_accuracy: 0.8580\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 7s 652us/step - loss: 0.2117 - accuracy: 0.9124 - val_loss: 0.4186 - val_accuracy: 0.8560\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 7s 653us/step - loss: 0.2193 - accuracy: 0.9086 - val_loss: 0.4200 - val_accuracy: 0.8520\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 7s 650us/step - loss: 0.2074 - accuracy: 0.9112 - val_loss: 0.4284 - val_accuracy: 0.8530\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 6s 643us/step - loss: 0.2088 - accuracy: 0.9095 - val_loss: 0.4355 - val_accuracy: 0.8460\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 7s 652us/step - loss: 0.1982 - accuracy: 0.9153 - val_loss: 0.4224 - val_accuracy: 0.8510\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 7s 672us/step - loss: 0.1990 - accuracy: 0.9149 - val_loss: 0.4208 - val_accuracy: 0.8530\n",
      "Epoch 105/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 576us/step - loss: 0.1985 - accuracy: 0.9158 - val_loss: 0.4090 - val_accuracy: 0.8490\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 6s 572us/step - loss: 0.1914 - accuracy: 0.9178 - val_loss: 0.4058 - val_accuracy: 0.8610\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 6s 583us/step - loss: 0.1821 - accuracy: 0.9225 - val_loss: 0.4282 - val_accuracy: 0.8620\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 6s 578us/step - loss: 0.1754 - accuracy: 0.9284 - val_loss: 0.4434 - val_accuracy: 0.8600\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 6s 576us/step - loss: 0.1781 - accuracy: 0.9260 - val_loss: 0.4216 - val_accuracy: 0.8660\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 6s 576us/step - loss: 0.1809 - accuracy: 0.9241 - val_loss: 0.3950 - val_accuracy: 0.8680\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 6s 585us/step - loss: 0.1662 - accuracy: 0.9348 - val_loss: 0.4067 - val_accuracy: 0.8670\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 6s 577us/step - loss: 0.1575 - accuracy: 0.9373 - val_loss: 0.3828 - val_accuracy: 0.8660\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 6s 578us/step - loss: 0.1538 - accuracy: 0.9356 - val_loss: 0.3888 - val_accuracy: 0.8590\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 6s 580us/step - loss: 0.1510 - accuracy: 0.9378 - val_loss: 0.4082 - val_accuracy: 0.8770\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 6s 578us/step - loss: 0.1542 - accuracy: 0.9392 - val_loss: 0.3851 - val_accuracy: 0.8810\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 6s 581us/step - loss: 0.1437 - accuracy: 0.9426 - val_loss: 0.4436 - val_accuracy: 0.8710\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 6s 574us/step - loss: 0.1502 - accuracy: 0.9411 - val_loss: 0.4023 - val_accuracy: 0.8790\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 6s 578us/step - loss: 0.1416 - accuracy: 0.9435 - val_loss: 0.3683 - val_accuracy: 0.8800\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 6s 576us/step - loss: 0.1310 - accuracy: 0.9479 - val_loss: 0.3759 - val_accuracy: 0.8790\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 6s 581us/step - loss: 0.1333 - accuracy: 0.9505 - val_loss: 0.3752 - val_accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "history = model.fit([story_train,question_train],answer_train,epochs=120,batch_size = 32,validation_data=([story_test,question_test],answer_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file ='sachin_chatbot_120.h5'\n",
    "model.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model on given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 38)\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('sachin_chatbot_120.h5')\n",
    "predict_results = model.predict(([story_test,question_test]))\n",
    "print(predict_results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.8857692e-20 1.5202489e-20 2.0125127e-20 2.1908042e-20 1.8064080e-20\n",
      " 1.6890261e-20 2.2058485e-20 1.4988909e-20 1.9828918e-20 2.2033340e-20\n",
      " 2.2154283e-20 2.1789690e-20 1.5331487e-20 1.8313654e-20 1.6595704e-20\n",
      " 2.1956735e-20 1.6579504e-20 1.9694959e-20 1.4946713e-20 2.2446577e-20\n",
      " 1.7015916e-20 1.6108073e-20 1.9271265e-20 2.0889335e-20 1.7490484e-20\n",
      " 1.9025543e-20 1.7298587e-20 1.8062634e-20 1.8110515e-20 1.9898403e-20\n",
      " 2.0306195e-20 1.6983687e-20 1.7130935e-20 2.0199502e-20 1.8519891e-08\n",
      " 1.0000000e+00 2.0071000e-20 2.4801873e-20]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "print(predict_results[0])\n",
    "print('-'*100)\n",
    "print(np.argmax(predict_results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_answers_idx = np.argmax(predict_results,axis=1)\n",
    "final_answers_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 35, 35, 34, 34, 35, 35, 34, 35, 34])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_answers_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes', 'no', 'yes']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Generate actual prediction from model\n",
    "words_dict = tokenizer.index_word\n",
    "final_answer_value = [words_dict.get(i) for i in final_answers_idx]\n",
    "final_answer_value[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We are done with our work!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Testing on custom generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_story = 'Sandra moved to kitchen . Sandra picked football . Sandra went back to the garden .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_question = 'Is Sandra in the kitchen ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_data = [(custom_story.split(),custom_question.split(),'no')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_story_vec,custom_question_vec,custom_answer = vectorize_data(custom_data,tokenizer.word_index,max_story_length,max_question_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 29, 15, 16, 20,\n",
       "         13, 29, 17, 24, 13, 29, 14,  1, 16, 31,  7, 13]], dtype=int32),\n",
       " array([[28, 29,  8, 31, 20, 12]], dtype=int32),\n",
       " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_story_vec,custom_question_vec,custom_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.30988997e-13, 1.08587889e-13, 1.18585439e-13, 1.24269356e-13,\n",
       "        1.18627059e-13, 1.29886119e-13, 1.36877367e-13, 1.09185196e-13,\n",
       "        1.19692762e-13, 1.15861829e-13, 1.07033956e-13, 1.15823610e-13,\n",
       "        1.13956831e-13, 1.18843791e-13, 1.30621249e-13, 1.19475393e-13,\n",
       "        1.23713594e-13, 1.27218264e-13, 1.15581955e-13, 1.50375684e-13,\n",
       "        1.25063534e-13, 1.28208696e-13, 1.21747285e-13, 1.09218732e-13,\n",
       "        1.13798267e-13, 1.15169118e-13, 1.08866197e-13, 1.28032513e-13,\n",
       "        1.08888213e-13, 1.20155947e-13, 1.10035455e-13, 1.08875331e-13,\n",
       "        1.20239634e-13, 1.18248659e-13, 5.73500022e-02, 9.42649961e-01,\n",
       "        1.16080810e-13, 1.12939816e-13]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_pred = model.predict(([custom_story_vec,custom_question_vec]))\n",
    "custom_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_max = np.argmax(custom_pred[0])\n",
    "val_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted answer is: \", tokenizer.index_word[val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of certainty was: 94.26 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability of certainty was: {:.2f} %\".format(custom_pred[0][val_max]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great Job!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
